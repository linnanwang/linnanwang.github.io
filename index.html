<!DOCTYPE html>
<!-- saved from url=(0045)http://3dvision.princeton.edu/people/shurans/ -->
<html class="gr__3dvision_princeton_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Linnan Wang</title>
	<link rel="stylesheet" type="text/css" href="pvg.css">
</head>
<body data-gr-c-s-loaded="true">
<!-- <script type="text/javascript" src="header.js"></script> -->

<br>
<table style="margin-top: 20px;">
<tbody>
<tr >
    <td style="width: 300px;" align="left" >
        <img src="profile.jpg" style="width: 240px;">
    </td>

    <td align="left">
        <h1>王林楠 (Linnan Wang)</h1>
        <p>
        Office 351, CIT<br>
        Department of Computer Science<br>
        Brown University<br>
        Providence, RI 02906<br>
        </p>

        <p> 
        <a href="https://scholar.google.com/citations?user=k1cGv3MAAAAJ&hl=en"> 
        <b>  Google Scholar </b> 
        </a> 
        |&nbsp;
        <a href="https://github.com/linnanwang"> 
		<b>  GitHub </b>
		</a>
        |&nbsp;
        <a href="https://www.linkedin.com/in/linnan-wang-50451460"> 
        <b> LinkedIn </b> 
        </a>
        </p>
     </td>
	 
    <td style="width: 330px;" align="right">
         <img src="logo.png" style="width: 220px;">
     </td>
</tr>
</tbody>
</table>

<h2>My Mission:</h2>

<p>Artificial Intelligence (AI) is going to be the extension of our brains, in the same way as cars are the extension of our legs. It has already been an indispensable part of our life. Every day, AI navigates us to places, answers our queries, and recommends restaurants and movies. Overall, it amplifies what we do, augmenting our memory, giving you instant knowledge, allowing us to concentrate on doing things that are properly human. </p>

<p> However, designing new AI models is still reserved for experts; and the goal of my research is to democratize AI, making it accessible to everybody, such that any person regardless of their prior experiences, and any company regardless of size can deploy sophisticated AI solutions with only a few simple clicks. </p>

<p>
I'm a Ph.D. student at the CS department of Brown University, advised by Prof.<a href="http://cs.brown.edu/~rfonseca/">Rodrigo Fonseca</a>. 
Before Brown, I was a <a href="https://www.omscs.gatech.edu"> OMSCS </a> student at Gatech while being a full time software developer at <a href="https://www.dowjones.com"> Dow Jones</a>. I acquired my bachelor degree from <a href="http://en.uestc.edu.cn/"> 
University of Electronic Science and Technology of China (UESTC) </a> at the beautiful Qing Shui He campus in 2011. I also work closely with 
<a href="https://scholar.google.com/citations?user=prjpMeoAAAAJ&hl=en">Yiyang Zhao</a>,
<a href="https://scholar.google.com/citations?user=bsN1uT0AAAAJ&hl=en">Junyu Zhang</a>,
<a href="https://scholar.google.com/citations?user=0mgEF28AAAAJ&hl=en">Yuandong Tian</a>,
<a href="https://scholar.google.com/citations?user=Y2GtJkAAAAAJ&hl=en">Saining Xie</a>,
<a href="https://scholar.google.com/citations?user=dXzhoLgAAAAJ&hl=en">Yi Yang</a>,
<a href="https://scholar.google.com/citations?user=PCCajlEAAAAJ&hl=en">Wei Wu</a>, and 
<a href="https://scholar.google.com/citations?user=37MF6fUAAAAJ&hl=en">George Bosilca</a>.
</p>





<h2>Publications:</h2>


<table id="pubList" border="0" cellpadding="0" width="100%" style="border-spacing: 0 6px; line-height:14pt;">
	<tbody>
		
	<tr style="border-width: 1px">
		<td><img src="moo_IRB.png" height = "300" width = "430" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Zhao, Yiyang, Linnan Wang</b> (equally contributed), Yuandong Tian, Rodrigo Fonseca, Tian Guo<br>
			<a href=""> Neural Architecture Search via Multi-Objective Optimization </a> <br>
 			<a href="">Paper to appear</a>&nbsp;
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
		
	<tr style="border-width: 1px">
		<td><img src="few_shot_nas2.png" height = "270" width = "400" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Zhao, Yiyang, Linnan Wang</b> (equally contributed), Yuandong Tian, Rodrigo Fonseca, Tian Guo<br>
			<b>ICML-2021, Long Oral</b>&nbsp;·&nbsp;Acceptance Rate: 21%&nbsp;·&nbsp;International Conference on Machine Learning<br>
			<a href="https://arxiv.org/pdf/2006.06863.pdf"> Few-shot Neural Architecture Search </a> <br>
 			<a href="https://arxiv.org/pdf/2006.06863.pdf">Paper</a>&nbsp;·&nbsp;
			<a href="https://github.com/aoiang/few-shot-NAS">Code</a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
	
	<tr style="border-width: 1px">
		<td><img src="latent-actions-teaser.jpg" height = "270" width = "400" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Wang, Linnan</b>, Saining Xie, Teng Li, Rodrigo Fonseca, Yuandong Tian<br>
			<a href="latent-actions.pdf"> Sample-Efficient Neural Architecture Search by Learning Action Space for Monte Carlo Tree Search</a> <br>
			<b>TPAMI-2021</b>&nbsp;·&nbsp;IEEE Transactions on Pattern Analysis and Machine Intelligence<br>
 			<a href="latent-actions.pdf">Paper</a>&nbsp;·&nbsp;
			<a href="https://www.youtube.com/watch?v=rXPHhHAgecY">FB Internal Pitch</a>&nbsp;·&nbsp;
			<a href="https://github.com/facebookresearch/LaMCTS">Code</a>&nbsp; <br>
			<a href="https://github.com/facebookresearch/LaMCTS/tree/master/LaNAS/LaNet"><b>Our agent designs a neural network that reaches 99% top-1 accuracy on CIFAR-10.</b></a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
		
	<tr style="border-width: 1px">
		<td><img src="lamcts.png" height = "700" width = "400" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Wang, Linnan</b>, Rodrigo Fonseca, Yuandong Tian<br>
			<a href="http://arxiv.org/abs/2007.00708"> Learning Search Space Partition for Black-box
Optimization using Monte Carlo Tree Search</a> <br>
			<b>NeurIPS-2020</b>&nbsp;·&nbsp; Acceptance Rate: 20%&nbsp;·&nbsp;Advances in Neural Information Processing Systems<br>
 			<a href="http://arxiv.org/abs/2007.00708">Paper</a>&nbsp;·&nbsp;
			<a href="nips-2020-poster.pdf">Poster</a>&nbsp;·&nbsp;
			<a href="https://github.com/facebookresearch/LaMCTS">Code</a>&nbsp; <br>
			<a href="https://bbochallenge.com/leaderboard"><b>LA-MCTS is used by the 3rd (JetBrains) and 8th place (KAIST) teams in the NeurIPS black-box optimization challenge.</b></a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
		
	<tr style="border-width: 1px">
		<td><img src="mcts_viz.png" height = "270" width = "400" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Wang, Linnan</b>, Yiyang Zhao, Yuu Jinnai, Yuandong Tian, Rodrigo Fonseca<br>
			<a href="https://arxiv.org/abs/1805.07440"> Neural Architecture Search using Deep Neural Networks and Monte Carlo Tree Search </a> <br>
			<b>AAAI-2020</b>&nbsp;·&nbsp; Acceptance Rate: 16%&nbsp;·&nbsp; AAAI conference on Artificial Intelligence<br>
 			<a href="https://arxiv.org/abs/1805.07440">Paper</a>&nbsp;·&nbsp;
			<a href="AlphaX_AAAI.pdf">Poster</a>&nbsp;·&nbsp;
			<a href="https://github.com/linnanwang/AlphaX-NASBench101"> Code </a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
	
	<tr style="border-width: 1px">
		<td><img src="compression_teaser.jpg" height = "270" width = "400" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Wang, Linnan</b>, Wei Wu, Junyu Zhang, Hang Liu, George Bosilca, Maurice Herlihy, Rodrigo Fonseca <br>
			<a href="gc.pdf"> SuperNeurons: FFT-based Gradient Sparsification in the Distributed Training of Deep Neural Networks</a> <br>
			<b>HPDC-2020</b> &nbsp;·&nbsp; Acceptance Rate: 18% &nbsp;·&nbsp; ACM Symposium on High-Performance Parallel and Distributed Computing<br>
 			<a href="gc.pdf">Paper</a>&nbsp;·&nbsp;
			<a href="https://www.youtube.com/watch?v=AbqfV0Im_YA&feature=youtu.be">Talk</a>&nbsp;·&nbsp;
			<a href="https://github.com/linnanwang/superneurons-release"> Code </a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
	
    <tr style="border-width: 1px">
 		<td><img src="superneurons.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
 			<p><b>Wang, Linnan</b>, Jinmian Ye, Yiyang Zhao, Wei Wu, Ang Li, Shuaiwen Leon Song, Zenglin Xu, Tim Kraska<br>
 			<a href="https://dl.acm.org/citation.cfm?id=3178491">SuperNeurons: Dynamic GPU Memory Management for Training Deep Nonlinear Neural Networks</a><br>
 				<b>PPoPP-2018</b>&nbsp;·&nbsp; Acceptance Rate: 21% &nbsp;·&nbsp; ACM Symposium on Principles and Practice of Parallel Programming <br>
 				<a href="https://dl.acm.org/citation.cfm?id=3178491">Paper</a>&nbsp;·&nbsp;
 				<a href="https://www.youtube.com/watch?v=y2h5AOwMnYs">Talk</a>&nbsp;·&nbsp;
				<a href="superneurons_talk.pptx"> Presentation </a>&nbsp;·&nbsp;
				<a href="https://github.com/linnanwang/superneurons-release"> Code </a> &nbsp;
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>			
 		</td>
    </tr>
	
    <tr style="border-width: 1px">
 		<td><img src="isgd.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
 			<p> <b>Wang, Linnan</b>, Yi Yang, Renqiang Min, and Srimat Chakradhar<br>
 			<a href="http://www.sciencedirect.com/science/article/pii/S0893608017301399">
 			Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent</a><br>
 			    <b>Neural Networks-2017</b><br>
 				<a href="http://www.sciencedirect.com/science/article/pii/S0893608017301399">Paper</a>&nbsp;·&nbsp;
 				<a href="https://patents.google.com/patent/US20170228645A1/en?q=Accelerating&q=deep&q=neural+network&q=training&q=inconsistent&q=stochastic+gradient+descent">Patent</a>
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>			
 		</td>
    </tr>
	
    <tr style="border-width: 1px">
 		<td><img src="BLASX.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
 			<p><b>Wang, Linnan</b>, Wei Wu, Zenglin Xu, Jianxiong Xiao, and Yi Yang<br>
 			<a href="http://dl.acm.org/citation.cfm?id=2926256">BLASX: A High Performance Level-3 BLAS Library for Heterogeneous MultiGPU Computing</a><br>
 				<b>ICS-2016</b>&nbsp;·&nbsp;Acceptance Rate: 24%&nbsp;·&nbsp; International Conference on Supercomputing  <br> 
 				<a href="http://dl.acm.org/citation.cfm?id=2926256">Paper</a>&nbsp;·&nbsp;
 				<a href="http://sc15.supercomputing.org/sites/all/themes/SC15images/tech_poster/poster_files/post108s2-file2.pdf">Poster</a>&nbsp;·&nbsp;
 				<a href="https://github.com/linnanwang/BLASX">Code</a>&nbsp;·&nbsp;
 				<a href="blasx_talk.pptx">Presentation</a>&nbsp;
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>			
 		</td>
    </tr>
	
    <tr style="border-width: 1px">
 		<td><img src="trnn.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
 			<p>Ye, Jinmian, <b>Linnan Wang</b>, Guangxi Li, Di Chen, Shandian Zhe, Xinqi Chu, Zenglin Xu <br>
 			<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.pdf">Learning Compact Recurrent Neural Networks with Block-Term Tensor Decomposition</a><br>
			<b>CVPR-2018</b>&nbsp;·&nbsp; Acceptance Rate: 29.6%&nbsp;·&nbsp;IEEE Conference on Computer Vision and Pattern Recognition<br>
 			<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.pdf">Paper</a>&nbsp;·&nbsp;
			<a href="cvpr_poster.pdf">Poster</a>&nbsp; 
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>
 		</td>
    </tr>
	
	
	<tr style="border-width: 1px">
		<td><img src="adapt.png" height = "270" width = "400"></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			Luo, Xi , Wei Wu, George Bosilca, Thananon Patinyasakdikul, <b>Linnan Wang</b>, Jack Dongarra<br>
			<a href="https://dl.acm.org/citation.cfm?id=3208054"><b>ADAPT: An Event-based Adaptive Collective Communication Framework</b> </a> <br>
			<b>HPDC-2018</b>&nbsp;·&nbsp;Acceptance Rate: 20%&nbsp;·&nbsp;ACM Symposium on High-Performance Parallel and Distributed Computing <br>
 			<a href="https://dl.acm.org/citation.cfm?id=3208054">Paper</a>&nbsp;·&nbsp; 
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
	
	<tr style="border-width: 1px">
		<td><img src="warp_consolidation.png" height = "270" width = "400"></td>
		<td>
			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			Li, Ang, Weifeng Liu, <b>Linnan Wang</b>, Kevin Barker, Shuaiwen Leon Song<br>
			<a href="http://www.idi.ntnu.no/~weifengl/papers/warpconsolidation_li_ics18.pdf"> <b>Warp-Consolidation: A Novel Execution Model for Modern GPUs</b> </a> <br>
			<b>ICS-2018</b>&nbsp;·&nbsp;Acceptance Rate: 26%&nbsp;·&nbsp;International Conference on Supercomputing<br>
 			<a href="http://www.idi.ntnu.no/~weifengl/papers/warpconsolidation_li_ics18.pdf">Paper</a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody></table>			
		</td>
	</tr>
	
    <tr style="border-width: 1px">
 		<td><img src="efficient_comm.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
 			<p> Zhao, Yiyang, <b>Linnan Wang</b>, Wei Wu, George Bosilca, Richard Vuduc, Jinmian Ye, Wenqi Tang, and Zenglin Xu. <br>
 			<a href="http://www.icl.utk.edu/files/publications/2017/icl-utk-966-2017.pdf">
 			<b>Efficient Communications in Training Large Scale Neural Networks</b></a><br>
 			<b>MM-2017</b>, workshop in ACM international conference on Multimedia<br>	
 			<a href="http://www.icl.utk.edu/files/publications/2017/icl-utk-966-2017.pdf">Paper</a>
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>			
 		</td>
    </tr>
   
   </tbody>
</table>




<h2>Projects:</h2>
	
<table id="pubList" border="0" cellpadding="0" width="100%" style="border-spacing: 0 6px; line-height:14pt;">

    <tr style="border-width: 1px">
		
 		<td style="text-align: left;">
		    <b>Automated Machine Learning</b>: building an AI that builds AI. <br>
 			<table style="width: 100%;">
				<tbody>
					<tr>
					<td style="width: 100%; text-align: left;">
 						<p> 
				  	  	  <li>
				  		  <b>AlphaX</b>: inspired by AlphaGo, we build the very first NAS search algorithm based on Monte Carlo Tree Search (MCTS). We showed Neural Networks designed by AlphaX improve the downstream applications such as detection, style transfer, image captioning, and many others. 
				  	      </li>
 						</p>
						<p>
 				  		   <a href="https://github.com/linnanwang/AlphaX-NASBench101">Github: https://github.com/linnanwang/AlphaX-NASBench101</a> </br>
						</p>
 					</td>
 					</tr>
					
					<tr>
					<td style="width: 100%; text-align: left;">
						<p>
						<li>
 						 <b>LA-MCTS</b>: we find that different action space used in MCTS significantly affects the search efficiency, which motivates the idea of learning action space for MCTS (LA-MCTS). This project contains 1) a distributed version that is scalable to hundreds of GPUs to push SoTA results, and 2) a one-shot version that let you get a working result within a few GPU days. You can find the entire pipeline (search and training) for doing NAS here. </br></br>
						With LA-MCTS, we have achieved SoTA results on many CV tasks including CIFAR-10, ImageNet and detection. Besides, LA-MCTS also achieves strong performance in general black-box optimization and reinforcement learning benchmarks, in particular for high-dimensional problems.
						</li>
						</p>
						<p>
 				  		   <a href="https://github.com/facebookresearch/LaMCTS">Github: https://github.com/facebookresearch/LaMCTS</a> </br>
						</p>
 					</td>
 					</tr>
					
				</tbody>
			</table>			
 		</td>
    </tr>
	
    <tr style="border-width: 1px">
 		<td style="text-align: left;">
		    <b>Machine Learning System</b>: building efficient distributed systems for AI. <br>
 			<table style="width: 100%;">
				<tbody>
					<tr>
					<td style="width: 100%; text-align: left;">
 						<p> 
				  	  	  <li>
				  		  <b>SuperNeurons</b>: this project builds a C++ Deep Learning framework, which features a dynamic GPU memory scheduling run-time to enable the neural network training far beyond the GPU DRAM capacity, and a FFT based gradient compression protocol for the efficient distributed DNN training. 
				  	      </li>
 						</p>
						<p>
 				  		   <a href="https://github.com/linnanwang/superneurons-release">Github: https://github.com/linnanwang/superneurons-release</a> </br>
						</p>
 					</td>
 					</tr>
					
					<tr>
					<td style="width: 100%; text-align: left;">
						<p>
						<li>
 						 <b>BLASX</b>: this project builds a level-3 BLAS library for heterogeneous multiGPUs. Due to the novel tile-cache design to avoid unnecessarily data-swapping, BLASX is 30% faster than commercial cuBLAS-XT from NVIDIA.</p>
						</li>
						<p>
 				  		   <a href="https://github.com/linnanwang/BLASX">Github: https://github.com/linnanwang/BLASX</a> </br>
						</p>
 					</td>
 					</tr>
					
				</tbody>
			</table>			
 		</td>
    </tr>
	
</table>

<h2>Patent:</h2>
<ul>
<li><a href="https://patents.google.com/patent/US20170228645A1/en?q=Accelerating&q=deep&q=neural+network&q=training&q=inconsistent&q=stochastic+gradient+descent"> US20170228645A1</a>,  Inconsistent Stochastic Gradient Descent, NEC Labs
</li>
</ul>


<h2>Awards:</h2>
<ul>
<li> Brown Fellowship (2017, 2020) </li>
<li> PPoPP Travel Grant (2018) </li>
<li> Finalist, Facebook Fellowship (2019) </li>
<li> Top Reviewer, NeurIPS (2020) </li>
</ul>


<h2>Academic Services:</h2>
<ul>
<li>Reviewer of International Conference on Intelligent Robots and Systems (IROS)</li>
<li>Reviewer of International Conference on Computer Vision (ICCV)</li>	
<li>Reviewer of Conference on Computer Vision and Pattern Recognition (CVPR)</li>	
<li>Reviewer of AAAI conference on Artificial Intelligence (AAAI)</li>	
<li>Reviewer of International Conference on Machine Learning (ICML)</li>
<li>Reviewer of Neural Information Processing System (NIPS)</li>
<li>Reviewer of International Conference on Learning Representations (ICLR)</li>
<li>Reviewer of IEEE Transactions on Evolutionary Computation (TEC)</li>
<li>Reviewer of Neural Architecture Search workshop (NAS-2020, NAS-2021) at ICLR</li>
<li>Reviewer of International Journal of Intelligent Systems (IJIS)</li>
<li>Reviewer of International Journal of Computer Vision (IJCV)</li>
<li>Reviewer of IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
<li>Reviewer of Journal of Machine Learning Research (JMLR)</li>
<li>Reviewer of Computer Vision and Image Understanding (CVIU)</li>
<li>Reviewer of Neural Computing and Applications (NCAA)</li>
<li>Reviewer of Neural Networks</li>
<li>Reviewer of IEEE Transactions on Emerging Topics in Computing (TETC)</li>
<li>Reviewer of Journal of Computer Science and Technology (JCST)</li>
<li>Reviewer of IEEE Transactions on Computers (TC)</li>
<li>Reviewer of IEEE Transactions on Parallel and Distributed Systems (TPDS)</li>
</ul>


<h2>Professional Experiences:</h2>
<ul>
<li>External Research Collaborator, Facebook AI Research, Menlo Park, 2019.Sept ~ Present, supervised by Yuandong Tian </li>
<li>Research Intern, Facebook AI Research, Menlo Park, 2019.Jan ~ 2019.May, supervised by Yuandong Tian </li>
<li>Research Intern, Microsoft Research AI, Redmond, 2018.May ~ 2018.August, supervised by Yuxiong He </li>
<li>Research Intern, NEC Labs, Princeton, 2016.Aug ~ 2017.Jan, supervised by Yi Yang </li>
<li>Software Developer, Dow Jones, Princeton, 2014.Aug ~ 2016.Aug </li>
</ul>

</body></html>
